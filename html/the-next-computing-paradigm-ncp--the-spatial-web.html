<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>The Spatial Web | HiPEAC Vision</title>
    <meta name="description" content="Drawing on the expertise of HiPEAC's 2,000-strong European network of experts, the HiPEAC Vision acts as a strategic roadmap for the European computing community. It sets out the main technology trends and challenges in computing and explores what these will mean for research, business, and society in general.">
    <meta name="generator" content="VitePress v1.0.0-rc.32">
    <link rel="preload stylesheet" href="/assets/style.Lq3SR4Sn.css" as="style">
    
    <script type="module" src="/assets/app.YNEQCMLI.js"></script>
    <link rel="modulepreload" href="/assets/chunks/framework.tzssv0c6.js">
    <link rel="modulepreload" href="/assets/chunks/theme.uIWEciYu.js">
    <link rel="modulepreload" href="/assets/the-next-computing-paradigm-ncp--the-spatial-web.md.CxNWqoHD.lean.js">
    <meta name="theme-color" content="#005eb8">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&amp;family=Roboto+Slab:wght@400;600&amp;display=swap">
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5a346dfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5a346dfe data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-d83f3580><div class="container" data-v-d83f3580><div class="title" data-v-d83f3580><div class="VPNavBarTitle has-sidebar" data-v-d83f3580 data-v-86d1bed8><a class="title" href="/" data-v-86d1bed8><!--[--><!--]--><!--[--><img class="VPImage logo" src="/hipeac.svg" alt data-v-8426fc1a><!--]--><!--[-->HiPEAC Vision<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-d83f3580><div class="curtain" data-v-d83f3580></div><div class="content-body" data-v-d83f3580><!--[--><!--]--><div class="VPNavBarSearch search" data-v-d83f3580><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-d83f3580 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/introduction--introduction.html" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Rationale</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://www.hipeac.net/vision/" target="_blank" rel="noreferrer" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>HiPEAC.net</span><!--]--></a><!--]--><!--]--></nav><!----><!----><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-d83f3580 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://www.youtube.com/@HiPEAC" aria-label="youtube" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>YouTube</title><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-d83f3580 data-v-d0bd9dde data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9c007e85><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-9c007e85><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><!----><!--[--><!--[--><!----><!----><div class="group" data-v-d0bd9dde><div class="item social-links" data-v-d0bd9dde><div class="VPSocialLinks social-links-list" data-v-d0bd9dde data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://www.youtube.com/@HiPEAC" aria-label="youtube" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>YouTube</title><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-d83f3580 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-5a346dfe data-v-f84a0989><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-f84a0989><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-f84a0989><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-f84a0989>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f84a0989 data-v-1c15a60a><button data-v-1c15a60a>Return to top</button><!----></div></div><aside class="VPSidebar" data-v-5a346dfe data-v-7f44e717><div class="curtain" data-v-7f44e717></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-7f44e717><span class="visually-hidden" id="sidebar-aria-label" data-v-7f44e717> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>Introduction</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/introduction--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible collapsed" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>The next computing paradigm (NCP)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/the-next-computing-paradigm-ncp--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/the-next-computing-paradigm-ncp--the-spatial-web.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>The Spatial Web</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/the-next-computing-paradigm-ncp--bridging-cps-communities.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Bridging CPS communities</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/the-next-computing-paradigm-ncp--ncp-societal-aspects.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>NCP societal aspects</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible collapsed" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>Artificial intelligence</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/artificial-intelligence--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/artificial-intelligence--ai-everywhere.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>AI everywhere</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/artificial-intelligence--ai-assisted-software-engineering.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>AI assisted software engineering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/artificial-intelligence--ai-for-eda.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>AI for EDA</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/artificial-intelligence--swot.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>SWOT</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible collapsed" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>New hardware</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/new-hardware--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/new-hardware--heterogeneous-and-domain-specific-acceleration.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Heterogeneous and domain-specific acceleration</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/new-hardware--quantum-computing.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Quantum computing</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/new-hardware--open-source-hardware.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Open source hardware</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible collapsed" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>Cybersecurity</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--ncp-cybersecurity.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>NCP cybersecurity</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--ncp-privacy.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>NCP privacy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--browser-tracking.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Browser tracking</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--dlt-and-ipfs-for-the-ncp.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>DLT and IPFS for the NCP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--integrity-of-hardware-supply-chains.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Integrity of hardware supply chains</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/cybersecurity--microarchitectures-as-root-of-trust.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Microarchitectures as root of trust</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-7f44e717><section class="VPSidebarItem level-0 collapsible collapsed" data-v-7f44e717 data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>Sustainability</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e31bd47b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-e31bd47b><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/sustainability--introduction.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/sustainability--what-does-it-mean-to-be-sustainable.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>What does it mean to be sustainable?</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/sustainability--sustainable-materials-and-production.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Sustainable materials and production</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/sustainability--sustainable-computer-systems.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>Sustainable computer systems</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5a346dfe data-v-669faec9><div class="VPDoc has-sidebar has-aside" data-v-669faec9 data-v-6b87e69f><!--[--><!--]--><div class="container" data-v-6b87e69f><div class="aside" data-v-6b87e69f><div class="aside-curtain" data-v-6b87e69f></div><div class="aside-container" data-v-6b87e69f><div class="aside-content" data-v-6b87e69f><div class="VPDocAside" data-v-6b87e69f data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-d330b1bb><div class="content" data-v-d330b1bb><div class="outline-marker" data-v-d330b1bb></div><div class="outline-title" role="heading" aria-level="2" data-v-d330b1bb>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-d330b1bb><span class="visually-hidden" id="doc-outline-aria-label" data-v-d330b1bb> Table of Contents for current page </span><ul class="root" data-v-d330b1bb data-v-d0ee3533><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-6b87e69f><div class="content-container" data-v-6b87e69f><!--[--><!--]--><!----><main class="main" data-v-6b87e69f><div style="position:relative;" class="vp-doc _the-next-computing-paradigm-ncp--the-spatial-web" data-v-6b87e69f><div><a target="_blank" href="https://doi.org/10.5281/zenodo.10874464"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.10874464.svg" alt="DOI" class="badge"></a><blockquote><p>We stand on the brink of a technological revolution where the web as we know it will break out from behind the screen and exist in the physical world along with us. Sometimes referred to as Web 3.0, the spatial web will seamlessly blend our physical and digital worlds together.</p></blockquote><h1 id="the-spatial-web-interconnecting-people-places-things-and-ai-for-a-smarter-world" tabindex="-1">The Spatial Web: interconnecting people, places, things and AI for a smarter world <a class="header-anchor" href="#the-spatial-web-interconnecting-people-places-things-and-ai-for-a-smarter-world" aria-label="Permalink to &quot;The Spatial Web: interconnecting people, places, things and AI for a smarter world&quot;">​</a></h1><p>by Philippe Sayegh, Safae Essafi Tremblay, Dan Richardson and Chase Pletts</p><p>The Spatial Web is a concept in the evolution of the internet that envisions a multi-dimensional online space intertwined with the physical world. Unlike the traditional two-dimensional web, the Spatial Web integrates digital information with physical locations and objects, creating a seamless blend between the digital realm of ones and zeroes, and the physical realm of places and spaces. This unifying web marks the evolution from a network of pages to one of spaces – cyber-physical and conceptual alike – and will interconnect activities, people, places and things, as well as AI to form a smarter world.</p><p>AI will join with existing and new Cyber Physical Systems (CPS), e.g., sensors and actuators, IoT devices and appliances, and autonomous vehicles, to become Autonomous Intelligent Systems (AIS), stemming from the fusion of AI, CPS and the IoT.</p><p>This paradigm shift will impact massively on the fabric of our professional, social, and personal life, creating smarter urban environments, advancing personalized healthcare and immersive educational experiences. Embedded computing devices will enable feedback loops where physical processes affect computational learning and vice versa.</p><p>The Spatial Web brings with it the possibility of creating a smarter world with new realms of possibility for individuals, organizations, and civilization as a whole.</p><h2 id="key-insights" tabindex="-1">Key insights <a class="header-anchor" href="#key-insights" aria-label="Permalink to &quot;Key insights&quot;">​</a></h2><ul><li><p>We&#39;re entering a new era of the internet: the “Spatial Web” – where the digital and physical worlds merge seamlessly, where compute and data knowledge will come out of our screens and into the world. This Spatial Web is sometimes called web 3.0, industry 4.0, the metaverse, or society 5.0, depending on your vantage point. It integrates AI with Cyber Physical Systems, creating automated and autonomous Intelligent Systems. It will revolutionize everything, from urban living to healthcare and education, making the world smarter and rich with new possibilities.</p></li><li><p>This next web will be a network of distributed intelligent agents (both human and machines) working together. To ensure that these autonomous systems understand, operate and connect with each other within the boundaries of safety, privacy, law, and ethics, new types of orchestration and governance will be needed.</p></li><li><p>The underlying infrastructure will need to be augmented and will require new socio-technical standards that are designed to provide governance capabilities, transparency, and auditability for autonomous agents and ecosystems of agents.</p></li><li><p>Furthermore, a shift in AI methodologies towards an approach based on Active Inference will enable AI that is transparent and explainable. AI agents that leverage the Active Inference framework are able to continuously sense, understand, predict, and act. This ongoing cycle produces AI that can adapt and evolve over time. They are explainable and self-learning by design.</p></li></ul><h2 id="key-recommendations" tabindex="-1">Key recommendations <a class="header-anchor" href="#key-recommendations" aria-label="Permalink to &quot;Key recommendations&quot;">​</a></h2><p>To propel the Spatial Web towards its maximal potential, we propose the following strategic initiatives:</p><ul><li><p>World Model Creation: Develop models based on standards and spatial and multidimensional data to simulate impactful scenarios.</p></li><li><p>Promotion of socio-technical standards: Advocate for standardization in adaptive computing and metadata.</p></li><li><p>Upskilling: Encourage talents to master the implementation and methodology of spatial web standards.</p></li><li><p>Join Collaborative Bodies: Participate in groups like the Spatial Web Foundation and the <a href="https://sagroups.ieee.org/2874/" target="_blank" rel="noreferrer">IEEE Spatial Web Working Group (P2874)</a>.</p></li><li><p>Awareness and Collaboration: Engage in hackathons and competence networks to drive adoption of Active Inference based AI.</p></li><li><p>Funding: Allocate funds to support startups and applications using these standards and active inference based AI.</p></li><li><p>Industry-wide Implementation: Collaboratively work on broad-scale implementation of socio-technical standards.</p></li></ul><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to &quot;&quot;">​</a></h2><h2 id="challenges-and-requirements" tabindex="-1">Challenges and requirements <a class="header-anchor" href="#challenges-and-requirements" aria-label="Permalink to &quot;Challenges and requirements&quot;">​</a></h2><p>With all this power for change comes great responsibility. The convergence of exponential technologies has the potential to test civilization as much as it can help it. This shift necessitates responsible stewardship and serious ethical consideration. As industries are transformed by AI and our quality of life improves, it will be critical that governance keeps pace with innovation.</p><p>The emergence of Autonomous Intelligent Systems (AIS) introduces an entirely new set of challenges. Advanced entities, such as autonomous drones, sophisticated manufacturing robots, and interactive companion devices, will operate autonomously, learn from their surroundings, and effect tangible changes in the real world. Ensuring universal interoperability becomes essential as the current 8 billion humans and 30 billion devices are expected to come online by 2030 to the Spatial Web.</p><p>Promoting this vision begs the following questions:</p><ul><li><p>How do we get all these diverse systems to talk to each other?</p></li><li><p>And once they can talk to each other, how do we govern these systems that are on the path to become self-governing?</p></li></ul><p>The answer lies in the foundation of the Spatial Web, i.e., an augmentation of the current internet infrastructure with new standards, a new approach to modeling data and to AI. The new standard infrastructure will become the fabric that we use to connect to AI, and that AI agents will use to connect with each other. These innovations will allow controlling how knowledge is structured and how information is shared on the network, also making it possible to build governance directly into the web itself. For this to happen, we need to upgrade the standards and protocols that are the backbone of the current Web 2.0.</p><h2 id="socio-technical-standards-enable-shared-understanding-between-humans-and-machines" tabindex="-1">Socio-technical Standards enable shared understanding between humans and machines <a class="header-anchor" href="#socio-technical-standards-enable-shared-understanding-between-humans-and-machines" aria-label="Permalink to &quot;Socio-technical Standards enable shared understanding between humans and machines&quot;">​</a></h2><p>The web as we know it today runs on a suite of technical standards, where HTML and HTTP have become predominant. The web technologies were not explicitly tailored to handle the demands for transactions, interoperability, security, and privacy, of contemporary complex systems and the connected smart world. However, they were open by design, which allowed for sufficient though laborious and creative adaptations.</p><p>As AI turns into an online commodity and becomes networked, the privacy and security challenges that are inherent in Web 2.0 technologies will grow exponentially. Ultimately, it may become impossible to course-correct as AI gets more and more powerful. It is therefore the case that we should turn our attention to the fundamental infrastructure of the web: the standards that define it.</p><p>Historically, society has deployed technical standards to foster safety and interoperability in the use of technology.</p><p>Considering the power of AI to alter virtually every sector of the world economy, technical standards aren’t enough. A new generation of web standards will also need to address social requirements around transparency, explainability, accountability, safety, and other societal or human-centered values.</p><p>A hybrid approach of socio-technical standards can bridge the gap between technology and society. Socio-technical standards could enable AI and AIS to be technically sound, socially beneficial, safe, compliant with laws, and able to be aligned with societal norms and values.</p><p>In 2020, The IEEE P2874 Spatial Web Working Group was formed to lead the development of socio-technical standards for AI and AIS alignment, interoperability, and governance. These standards are informed by IEEE’s Ethically-Aligned Design P7000 Series of standards that address human rights, well-being, accountability, and transparency for AI and AIS.</p><p>The IEEE P2874’s Spatial Web Standards are being developed to address the following:</p><ol><li><p>Shared understanding of meaning and context between humans and AIs.</p></li><li><p>Explainability of AI systems, enabled by the explicit modeling of their decision-making processes.</p></li><li><p>Interoperability of data and models that enable universal interaction and collaboration across organizations, networks, and borders.</p></li><li><p>Compliance features that are built to adapt by design with diverse local, regional, national, and international regulatory demands, cultural norms, and ethics.</p></li><li><p>Authentication and credentialing, driving compliance and control over critical activities, with privacy, security, and explainability built-in by design as well.</p></li></ol><p>These standards lay the foundations for the efficient integration and adoption of AI technologies while minimizing the risk inherent in AI. In the sequel, we highlight a few essential components of the Spatial Web Standards.</p><h3 id="socio-technical-standards-enable-comprehensive-world-modeling" tabindex="-1">Socio-technical Standards enable comprehensive world modeling <a class="header-anchor" href="#socio-technical-standards-enable-comprehensive-world-modeling" aria-label="Permalink to &quot;Socio-technical Standards enable comprehensive world modeling&quot;">​</a></h3><p>World modeling in AI involves creating internal representations of the external environment, utilizing abstract symbols to understand and interact effectively. However, this process encounters a crucial challenge known as the grounding problem. This challenge emerges when translating symbolic representations into a meaningful reflection of real-world entities, requiring a bridge between the abstract and the concrete. Successful world modeling addresses the grounding problem by integrating sensory input and learning from real-world interactions. The resolution of the grounding problem enhances the accuracy and context-awareness of AI systems, enabling them to navigate diverse environments with a deeper understanding.</p><p>The successful implementation of AIS is therefore dependent on their ability to create comprehensive and dynamic world models. AI and AIS systems will need hyperdimensional world modeling to enhance performance and explainability. These systems must be adept at understanding and interpreting complex models of the world from as many perspectives and sensory inputs as required by the problem they are trying to solve or the activity they are trying to predict and optimize. For IoT and cyber-physical systems to stay pertinent and adjust to shifting use cases and scenarios, data must be integrated within a broad world model.</p><p>World modeling is multi-dimensional. It encapsulates identities, activities, environments, policies and credentials, which need to be expressed in a coherent and shared manner in different contexts:</p><ul><li><p>Semantic (meaning and logic)</p></li><li><p>Spatial (physical and situational)</p></li><li><p>Societal (values and value)</p></li><li><p>Systems (networks and ecosystems)</p></li></ul><p>Comprehensive world modeling needs to:</p><ul><li><p>Be stateful</p></li><li><p>Be multi-modal / multi-dimensional</p></li><li><p>Be interpretable and actionable by machines</p></li><li><p>Be shareable between heterogeneous networks, devices and applications, and humans</p></li><li><p>Maintain coherence over time and space for all the actors/edges involved in a use case</p></li></ul><p>The Spatial Web socio-technical standards, Hyper-Spatial Modeling Language (HSML) and Hyper-Spatial Transaction Protocol (HSTP), enable world modeling by structuring spatial information and securing efficient transactions.</p><h3 id="hsml" tabindex="-1">HSML <a class="header-anchor" href="#hsml" aria-label="Permalink to &quot;HSML&quot;">​</a></h3><p>Hyper-Spatial Modeling Language is a knowledge modeling language that enables systems to encode properties of physical objects, logical concepts, and contextual activities. HSML facilitates multimodal world modeling and knowledge sharing among machines and humans, encompassing ethical, moral, economic, and societal considerations. HSML models relationships and activities, addressing the Who, What, When, Where, How, and Why.</p><p>HSML allows for the detailed description of entities and their relationships with other entities within the Spatial Web. It serves as a modeling language and semantic data ontology schema, crucial for creating complex and accurate models of spatial environments and contracts. By providing a framework for encoding these models in a way that is both human- and machine-readable, HSML facilitates the construction of dynamic, interactive world models.</p><p><img src="/assets/image2.adJhaLyQ.png" alt=""></p><h3 id="hstp" tabindex="-1">HSTP <a class="header-anchor" href="#hstp" aria-label="Permalink to &quot;HSTP&quot;">​</a></h3><p>Hyper-Spatial Transaction Protocol provides the methods for passing HSML messages in the Spatial Web. It provides a universal, secure, and verifiable protocol for communication between digital or physical systems, ensuring seamless interaction and cooperation between diverse AI systems. It incorporates a zero-trust architecture and strict authentication measures for secure data exchange and control over AI operations.</p><p><img src="/assets/image3.Mx44OCl1.png" alt=""><em>Figure 3. A simplified view of the HSTP query language.</em></p><p>HSTP manages the transactional aspect of models of spatial environments and contracts. It is designed to support automated contracting, ensuring decentralized, secure, and privacy-respecting interactions within the Spatial Web. By providing APIs for distributed computing platforms, HSTP enables smooth and secure exchange of information and resources within the modeled world, thereby supporting dynamic interactions and operations in world modeling.</p><p>HSTP’s zero-trust architecture ensures that data sharing across environments is done so with security and privacy principles embedded by design, in particular as it mandates verifiable credentials for any interaction between systems. This rigorous credential-based authentication process is particularly crucial for AI activities, as it allows them to operate within a secure and compliant framework, protecting against unauthorized access, ensuring the integrity of data and operations, and significantly enhancing the security and trustworthiness of all operations across the Spatial Web.</p><p><img src="/assets/image4.KiYxXCGd.png" alt=""></p><p>In contrast to the open structure of the Internet and the World Wide Web, the Spatial Web, based on HSTP, is designed as a permissioned network by design. This fundamental shift in architecture not only enhances security but also increases the reliability and predictability of AI operations within this environment.</p><h2 id="a-new-approach-to-ai" tabindex="-1">A new Approach to AI <a class="header-anchor" href="#a-new-approach-to-ai" aria-label="Permalink to &quot;A new Approach to AI&quot;">​</a></h2><p>The field of AI is at a critical juncture where traditional methods, often based on narrow, task-specific algorithms, are reaching their limits in terms of adaptability, generalizability, and understanding complex, real-world environments. This limitation calls for a new approach that can bridge the gap between highly specialized AI and the more versatile, adaptive intelligence seen in natural systems. Active Inference emerges as a promising answer to this challenge.</p><h3 id="active-inference" tabindex="-1">Active Inference <a class="header-anchor" href="#active-inference" aria-label="Permalink to &quot;Active Inference&quot;">​</a></h3><p>The framework of Active Inference decodes biological intelligence by analyzing how the human brain creates mental models and makes predictions based on those models. VERSES is now applying this framework to the fields of computer science and AI.</p><p>Originally developed by Karl Friston—most highly cited neuroscientist<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, theoretician at University College London, and Chief Science Officer at VERSES—active inference has the potential to completely transform the field of artificial intelligence by creating intelligent agents that can model the world, and use those models to think, plan, predict, and act.</p><p>Active inference defines in mathematical terms the process by which agents, whether living organisms or digital systems, learn by interacting with their environment. It posits that all intelligent agents are fundamentally engaged in minimizing the uncertainty between expected sensory inputs and actual sensory inputs. Agents make predictions about the world and then act to make those predictions come true. The goal is to reduce the level of surprise an agent experiences. The less uncertainty an agent must navigate, the better its chance of survival.</p><p>Active inference involves creating an internal representation of the external world. This world model enables active inference-based agents to make predictions about the causes of sensory inputs and the likely outcomes of actions.</p><p>As the agent takes action in the world, it may learn something new about its environment. It can then update its world model with this new information. Agents can also access a shared world model that is continuously updated by multiple agents, resulting in a world model that is shared and always up to date.</p><p>For AI and robotics, active inference offers a blueprint for creating systems that can autonomously learn and make informed decisions. These agents use predictions based on an always-up-to-date world model to guide their behavior, constantly adjusting their actions based on new data from the environment. This creates a feedback loop where the AI&#39;s actions are both informed by and inform its predictions, leading to a self-correcting system that can become more sophisticated over time.</p><p>The shift towards self-learning and agentive AI necessarily poses crucial regulatory questions – How do we effectively regulate a system inherently designed for self-regulation? The evolving nature of AIS and its potential autonomy raise urgent considerations for regulatory frameworks, prompting a need to strike a balance between fostering innovation and ensuring responsible governance.</p><h2 id="governance-and-regulations" tabindex="-1">Governance and Regulations <a class="header-anchor" href="#governance-and-regulations" aria-label="Permalink to &quot;Governance and Regulations&quot;">​</a></h2><p>Historically, laws have primarily focused on human-to-human interactions, where actors and subjects are humans or human-controlled entities. With the arrival of AI, however, there has been a shift in focus to human-to-AI interactions. This includes issues such as data privacy, algorithmic bias, intellectual property rights in AI-generated content, and questions around liability for decisions made by AI systems. Laws are being updated and new ones created to address these unique challenges, where the lines between the creator (human) and the creation (AI) are often blurred.</p><p>Looking ahead, there’s an anticipation that the legal system will need to evolve further to govern AI-to-AI interactions. This emerging field is likely to present unprecedented challenges. Key issues may include the autonomous decision-making by AI entities, interactions between different AI systems without direct human oversight, and the consequences of these interactions. For instance, two AI systems might negotiate contracts, conduct transactions, or even engage in conflict resolution without human intervention.</p><p>For AI systems to understand and apply laws, these laws must be converted into a format that machines can understand and process. This involves translating legal texts into structured data that can be easily understood in all contextual dimensions by computer algorithms. This would mean coding laws in a way that captures their essence and directives without ambiguity, which is a significant challenge given the complexity and nuanced nature of legal language. Beyond just being readable, laws need to be interpretable by AI. This means that the AI must be able to understand the intent, context, and application of the law. Developing a universally accepted socio-technical standard for how laws are encoded is therefore crucial. This ensures consistency in how different AI systems interpret and apply the law. Without standardization, there could be significant discrepancies in legal interpretations, leading to unpredictability and potential injustices. Moreover, laws evolve over time, responding to societal changes, new understandings, and precedents. AI systems will need to be adaptable to these changes, requiring mechanisms for continuous learning and updating of legal knowledge bases.</p><p>Additionally, machine-readable and interpretable laws must be accessible to those who are subject to them, including humans. This means that while laws need to be encoded for machines, they also need to be understandable by humans in a transparent manner, ensuring that the legal process remains open and fair. These laws also need to be explainable, in order to respond to auditability and liability concerns. It is crucial that the rationale behind automated legal decisions is clearly outlined and can be scrutinized. This ensures that in cases where disputes arise, or errors occur, there is a traceable decision-making process. This not only aids in holding systems and their creators accountable but also fosters trust in the technology by demonstrating that decisions are made based on logical and fair principles, and that there are mechanisms in place to rectify any mistakes or biases.</p><h3 id="ais-international-rating-system-airs" tabindex="-1">AIS International Rating System (AIRS) <a class="header-anchor" href="#ais-international-rating-system-airs" aria-label="Permalink to &quot;AIS International Rating System (AIRS)&quot;">​</a></h3><p>Intelligent machines may need to operate optimally across a range of governance frameworks, from centralized to federated to distributed. Standards that facilitate interoperability across the spectrum will be essential.</p><p>The chart below illustrates how AI systems that become increasingly intelligent gain the potential for greater autonomy, which is reflected in the corresponding governance framework that becomes available, along with all other governance frameworks that came before it.</p><p><img src="/assets/image5.Z5xIvY6b.png" alt=""><em>Figure 4: AIRS Chart sourced from: <a href="https://www.verses.ai/ai-governance" target="_blank" rel="noreferrer">The Future of Global AI Governance</a></em></p><div class="info custom-block"><p class="custom-block-title">AUTHORS</p><p><strong>Philippe Sayegh</strong> is chief adoption officer at VERSES.ai.</p><p><strong>Safae Essafi Tremblay</strong> is senior grant manager and researcher at VERSES.ai.</p><p><strong>Dan Richardson</strong> is director of market analysis at the Spatial Web Foundation.</p><p><strong>Chase Pletts</strong> is senior editor at VERSES.ai.</p></div><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://www.adscientificindex.com/scientist/karl-friston/1334989" target="_blank" rel="noreferrer">AD Scientific Index 2024</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section></div></div></main><footer class="VPDocFooter" data-v-6b87e69f data-v-48f9bb55><!--[--><!--]--><!----><nav class="prev-next" data-v-48f9bb55><div class="pager" data-v-48f9bb55><a class="VPLink link pager-link prev" href="/the-next-computing-paradigm-ncp--introduction.html" data-v-48f9bb55><!--[--><span class="desc" data-v-48f9bb55>Previous page</span><span class="title" data-v-48f9bb55>Introduction
</span><!--]--></a></div><div class="pager" data-v-48f9bb55><a class="VPLink link pager-link next" href="/the-next-computing-paradigm-ncp--bridging-cps-communities.html" data-v-48f9bb55><!--[--><span class="desc" data-v-48f9bb55>Next page</span><span class="title" data-v-48f9bb55>Bridging CPS communities
</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5a346dfe data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>The HiPEAC project has received funding from the European Union's Horizon Europe research and innovation funding programme under grant agreement number 101069836. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union. Neither the European Union nor the granting authority can be held responsible for them.</p><p class="copyright" data-v-e315a0ad>© 2004-2024 High Performance, Edge And Cloud computing</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"artificial-intelligence--ai-assisted-software-engineering.md\":\"fc7TKK7D\",\"artificial-intelligence--introduction.md\":\"IqHqC3AT\",\"artificial-intelligence--ai-for-eda.md\":\"Fumg4QfF\",\"artificial-intelligence--ai-everywhere.md\":\"miEojVWO\",\"cybersecurity--browser-tracking.md\":\"efNizEzS\",\"cybersecurity--dlt-and-ipfs-for-the-ncp.md\":\"Ndgj8ECx\",\"new-hardware--introduction.md\":\"tIIM2DLz\",\"artificial-intelligence--swot.md\":\"2ntY1JAw\",\"cybersecurity--introduction.md\":\"LXCUFuOa\",\"cybersecurity--ncp-privacy.md\":\"W3t5UzTe\",\"cybersecurity--microarchitectures-as-root-of-trust.md\":\"lyuirl-E\",\"new-hardware--open-source-hardware.md\":\"NPZFfDQz\",\"the-next-computing-paradigm-ncp--introduction.md\":\"6USYaFeg\",\"cybersecurity--integrity-of-hardware-supply-chains.md\":\"G1EwzHzZ\",\"index.md\":\"do55OOCi\",\"the-next-computing-paradigm-ncp--the-spatial-web.md\":\"CxNWqoHD\",\"new-hardware--heterogeneous-and-domain-specific-acceleration.md\":\"diIQB6a3\",\"introduction--introduction.md\":\"81IsH3iM\",\"sustainability--introduction.md\":\"XgbH_xtg\",\"sustainability--sustainable-materials-and-production.md\":\"EVRP2ZdI\",\"sustainability--sustainable-computer-systems.md\":\"fLi9Uoxf\",\"the-next-computing-paradigm-ncp--ncp-societal-aspects.md\":\"GeBBbizX\",\"sustainability--what-does-it-mean-to-be-sustainable.md\":\"1WT_ZJLz\",\"cybersecurity--ncp-cybersecurity.md\":\"IJeMuGgD\",\"new-hardware--quantum-computing.md\":\"Na2O_jz1\",\"the-next-computing-paradigm-ncp--bridging-cps-communities.md\":\"EK3XllHa\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en\",\"dir\":\"ltr\",\"title\":\"HiPEAC Vision\",\"description\":\"Drawing on the expertise of HiPEAC's 2,000-strong European network of experts, the HiPEAC Vision acts as a strategic roadmap for the European computing community. It sets out the main technology trends and challenges in computing and explores what these will mean for research, business, and society in general.\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":false,\"themeConfig\":{\"logo\":\"/hipeac.svg\",\"sidebar\":[{\"text\":\"Introduction\",\"collapsed\":false,\"items\":[{\"text\":\"Introduction\",\"link\":\"introduction--introduction\"}]},{\"text\":\"The next computing paradigm (NCP)\",\"collapsed\":true,\"items\":[{\"text\":\"Introduction\",\"link\":\"the-next-computing-paradigm-ncp--introduction\"},{\"text\":\"The Spatial Web\",\"link\":\"the-next-computing-paradigm-ncp--the-spatial-web\"},{\"text\":\"Bridging CPS communities\",\"link\":\"the-next-computing-paradigm-ncp--bridging-cps-communities\"},{\"text\":\"NCP societal aspects\",\"link\":\"the-next-computing-paradigm-ncp--ncp-societal-aspects\"}]},{\"text\":\"Artificial intelligence\",\"collapsed\":true,\"items\":[{\"text\":\"Introduction\",\"link\":\"artificial-intelligence--introduction\"},{\"text\":\"AI everywhere\",\"link\":\"artificial-intelligence--ai-everywhere\"},{\"text\":\"AI assisted software engineering\",\"link\":\"artificial-intelligence--ai-assisted-software-engineering\"},{\"text\":\"AI for EDA\",\"link\":\"artificial-intelligence--ai-for-eda\"},{\"text\":\"SWOT\",\"link\":\"artificial-intelligence--swot\"}]},{\"text\":\"New hardware\",\"collapsed\":true,\"items\":[{\"text\":\"Introduction\",\"link\":\"new-hardware--introduction\"},{\"text\":\"Heterogeneous and domain-specific acceleration\",\"link\":\"new-hardware--heterogeneous-and-domain-specific-acceleration\"},{\"text\":\"Quantum computing\",\"link\":\"new-hardware--quantum-computing\"},{\"text\":\"Open source hardware\",\"link\":\"new-hardware--open-source-hardware\"}]},{\"text\":\"Cybersecurity\",\"collapsed\":true,\"items\":[{\"text\":\"Introduction\",\"link\":\"cybersecurity--introduction\"},{\"text\":\"NCP cybersecurity\",\"link\":\"cybersecurity--ncp-cybersecurity\"},{\"text\":\"NCP privacy\",\"link\":\"cybersecurity--ncp-privacy\"},{\"text\":\"Browser tracking\",\"link\":\"cybersecurity--browser-tracking\"},{\"text\":\"DLT and IPFS for the NCP\",\"link\":\"cybersecurity--dlt-and-ipfs-for-the-ncp\"},{\"text\":\"Integrity of hardware supply chains\",\"link\":\"cybersecurity--integrity-of-hardware-supply-chains\"},{\"text\":\"Microarchitectures as root of trust\",\"link\":\"cybersecurity--microarchitectures-as-root-of-trust\"}]},{\"text\":\"Sustainability\",\"collapsed\":true,\"items\":[{\"text\":\"Introduction\",\"link\":\"sustainability--introduction\"},{\"text\":\"What does it mean to be sustainable?\",\"link\":\"sustainability--what-does-it-mean-to-be-sustainable\"},{\"text\":\"Sustainable materials and production\",\"link\":\"sustainability--sustainable-materials-and-production\"},{\"text\":\"Sustainable computer systems\",\"link\":\"sustainability--sustainable-computer-systems\"}]}],\"nav\":[{\"text\":\"Rationale\",\"link\":\"/introduction--introduction\"},{\"text\":\"HiPEAC.net\",\"link\":\"https://www.hipeac.net/vision/\"}],\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":\"youtube\",\"link\":\"https://www.youtube.com/@HiPEAC\"}],\"footer\":{\"message\":\"The HiPEAC project has received funding from the European Union's Horizon Europe research and innovation funding programme under grant agreement number 101069836. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union. Neither the European Union nor the granting authority can be held responsible for them.\",\"copyright\":\"© 2004-2024 High Performance, Edge And Cloud computing\"}},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>